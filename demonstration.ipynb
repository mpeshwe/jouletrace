{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9ad651",
   "metadata": {},
   "source": [
    "## Energy-Based Reward Function Demo\n",
    "\n",
    "This demo shows how we can use JouleTrace to compare two algorithms solving the same problem, and assign rewards based on their energy efficiency and execution time.\n",
    "\n",
    "**Scenario**: Computing Fibonacci numbers\n",
    "- **Fast candidate**: Iterative O(n) algorithm\n",
    "- **Slow candidate**: Naive recursive algorithm (exponential complexity)\n",
    "\n",
    "Both produce correct results, but we'll see how the reward function prefers the more efficient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf2865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# JouleTrace API configuration\n",
    "JOULETRACE_BASE_URL = os.getenv(\"JOULETRACE_BASE_URL\", \"http://127.0.0.1:8000\")\n",
    "MEASURE_URL = f\"{JOULETRACE_BASE_URL}/api/v1/measure\"\n",
    "\n",
    "def poll_from_poll_url(poll_url: str, timeout_s: int = 600, interval_s: float = 0.5):\n",
    "    \"\"\"Poll a JouleTrace task until completion.\"\"\"\n",
    "    url = poll_url if poll_url.startswith(\"http\") else f\"{JOULETRACE_BASE_URL}{poll_url}\"\n",
    "    start = time.time()\n",
    "    last_status = None\n",
    "    \n",
    "    while True:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        status = data.get(\"status\")\n",
    "        \n",
    "        if status != last_status:\n",
    "            print(f\"Status: {status}\")\n",
    "            last_status = status\n",
    "            \n",
    "        if status in {\"completed\", \"failed\"}:\n",
    "            return data\n",
    "            \n",
    "        if time.time() - start > timeout_s:\n",
    "            raise TimeoutError(f\"Polling timed out after {timeout_s}s\")\n",
    "            \n",
    "        time.sleep(interval_s)\n",
    "\n",
    "def queue_job(candidate_code, function_name, tests, timeout_seconds=15,\n",
    "              memory_limit_mb=2048, trials=3, warmup=1):\n",
    "    payload = {\n",
    "        \"candidate_code\": candidate_code,\n",
    "        \"function_name\": function_name,\n",
    "        \"test_cases\": tests,\n",
    "        \"timeout_seconds\": timeout_seconds,\n",
    "        \"memory_limit_mb\": memory_limit_mb,\n",
    "        \"energy_measurement_trials\": trials,\n",
    "        \"warmup_trials\": warmup,\n",
    "    }\n",
    "    return requests.post(MEASURE_URL, json=payload, timeout=60).json()\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bf7a8",
   "metadata": {},
   "source": [
    "## Define Candidate Algorithms\n",
    "\n",
    "We'll compare two implementations:\n",
    "1. **Fast (Iterative)**: O(n) time complexity, minimal memory usage\n",
    "2. **Slow (Naive Recursive)**: O(2^n) time complexity, significant call stack overhead\n",
    "\n",
    "Both are functionally correct, but dramatically different in efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe32713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast candidate (iterative):\n",
      "def solve(n):\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        a, b = b, a + b\n",
      "    return a\n",
      "\n",
      "\n",
      "Slow candidate (recursive):\n",
      "def solve(n):\n",
      "    if n < 2:\n",
      "        return n\n",
      "    return solve(n-1) + solve(n-2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fast candidate: Iterative approach (O(n))\n",
    "candidate_fast = \"\"\"\\\n",
    "def solve(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\"\"\"\n",
    "\n",
    "# Slow candidate: Naive recursion (O(2^n))\n",
    "candidate_slow = \"\"\"\\\n",
    "def solve(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return solve(n-1) + solve(n-2)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Fast candidate (iterative):\")\n",
    "print(candidate_fast)\n",
    "print(\"\\nSlow candidate (recursive):\")\n",
    "print(candidate_slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee2b4a",
   "metadata": {},
   "source": [
    "## Generate Test Cases\n",
    "\n",
    "We'll use modest Fibonacci indices (22, 24) so that even the slow recursive version completes within a reasonable timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac72d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:\n",
      "[{'expected_output': 17711, 'inputs': [22], 'test_id': 'fib-22'},\n",
      " {'expected_output': 46368, 'inputs': [24], 'test_id': 'fib-24'}]\n"
     ]
    }
   ],
   "source": [
    "# Local reference implementation to generate expected outputs\n",
    "def fib_ref(n: int) -> int:\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\n",
    "# Generate test cases\n",
    "test_inputs = [22, 24]\n",
    "tests = [\n",
    "    {\n",
    "        \"test_id\": f\"fib-{n}\",\n",
    "        \"inputs\": [n],\n",
    "        \"expected_output\": fib_ref(n)\n",
    "    }\n",
    "    for n in test_inputs\n",
    "]\n",
    "\n",
    "print(\"Test cases:\")\n",
    "pprint(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808958e7",
   "metadata": {},
   "source": [
    "## Energy Reward Function\n",
    "\n",
    "The reward function considers:\n",
    "- **Correctness**: Must pass all tests (otherwise -2.0 penalty)\n",
    "- **Energy consumption**: Lower is better (log-scaled for stability)\n",
    "- **Execution time**: Lower is better (log-scaled)\n",
    "- **Time budget**: Penalty if execution exceeds threshold\n",
    "\n",
    "**Formula**: `reward = 1.0 - wE*log(E) - wT*log(T) - penalty_if_slow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd58fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_reward(result_json: dict,\n",
    "                     ref_energy_j: float = 1.0,\n",
    "                     ref_time_s: float = 0.01,\n",
    "                     beta_energy: float = 1.5,   # >1 emphasizes energy over time; <1 does the opposite\n",
    "                     k_energy: float = 1.2,      # steepness for energy penalty\n",
    "                     k_time: float = 1.0,        # steepness for time penalty\n",
    "                     hard_cap_multiple: float = 50.0):\n",
    "    \"\"\"\n",
    "    Reward in [0,1], higher is better.\n",
    "    - Monotonically decreases with energy and time.\n",
    "    - Diminishing returns when already below the reference.\n",
    "    - Harmonic blending emphasizes the worse dimension.\n",
    "\n",
    "    Transform:\n",
    "      s(r; k) = 1 / (1 + r^k), where r is ratio to reference (>=0).\n",
    "      r = value / reference. If r=1 => s=0.5. If r<<1 => s→1. If r>>1 => s→0.\n",
    "    Blend:\n",
    "      F_beta-like harmonic mean: R = (1+β^2) * (Se * St) / (β^2 * Se + St)\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic validity checks\n",
    "    if result_json.get(\"status\") != \"completed\":\n",
    "        return 0.0\n",
    "    validation = result_json.get(\"validation\") or {}\n",
    "    if not validation.get(\"is_correct\", False):\n",
    "        return 0.0\n",
    "\n",
    "    em = result_json.get(\"energy_metrics\") or {}\n",
    "    E = em.get(\"median_total_energy_joules\")\n",
    "    T = em.get(\"median_execution_time_seconds\")\n",
    "    if E is None or T is None or E < 0 or T < 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Optional hard cap: if absurdly worse than reference, collapse reward\n",
    "    if E > hard_cap_multiple * ref_energy_j or T > hard_cap_multiple * ref_time_s:\n",
    "        return 0.0\n",
    "\n",
    "    # Dimensionless ratios\n",
    "    rE = E / max(ref_energy_j, 1e-12)\n",
    "    rT = T / max(ref_time_s, 1e-12)\n",
    "\n",
    "    # Smooth, bounded, monotone scores (1 is best, 0 is worst)\n",
    "    Se = 1.0 / (1.0 + (rE ** k_energy))\n",
    "    St = 1.0 / (1.0 + (rT ** k_time))\n",
    "\n",
    "    # F_beta-style harmonic mean emphasizing the weaker side\n",
    "    beta2 = beta_energy * beta_energy\n",
    "    denom = (beta2 * Se + St)\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    reward = (1.0 + beta2) * (Se * St) / denom\n",
    "\n",
    "    # Numerical safety & clamp\n",
    "    if not (reward == reward):  # NaN check\n",
    "        return 0.0\n",
    "    return float(max(0.0, min(1.0, reward)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bc6fe",
   "metadata": {},
   "source": [
    "## Run Energy Measurements\n",
    "\n",
    "Now we'll measure both candidates with JouleTrace and calculate their rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a8f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing slow candidate...\n",
      "Queueing fast candidate...\n",
      "\n",
      "Polling slow candidate...\n",
      "Status: running\n",
      "Status: completed\n",
      "\n",
      "Polling fast candidate...\n",
      "Status: completed\n",
      "\n",
      "Both measurements complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Queueing slow candidate...\")\n",
    "q_slow = queue_job(candidate_slow, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "\n",
    "print(\"Queueing fast candidate...\")\n",
    "q_fast = queue_job(candidate_fast, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "\n",
    "print(\"\\nPolling slow candidate...\")\n",
    "r_slow = poll_from_poll_url(q_slow[\"poll_url\"])\n",
    "\n",
    "print(\"\\nPolling fast candidate...\")\n",
    "r_fast = poll_from_poll_url(q_fast[\"poll_url\"])\n",
    "\n",
    "print(\"\\nBoth measurements complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78875e5",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "\n",
    "Let's calculate rewards and compare the two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8801bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENERGY EFFICIENCY COMPARISON\n",
      "======================================================================\n",
      "Metric                         Slow (Recursive)     Fast (Iterative)    \n",
      "----------------------------------------------------------------------\n",
      "Status                         completed            completed           \n",
      "Correctness                    True                 True                \n",
      "Energy                         1.730 J              1.140 J             \n",
      "Time                           10.159 ms            6.503 us            \n",
      "----------------------------------------------------------------------\n",
      "REWARD SCORE                   0.4353               0.7350              \n",
      "======================================================================\n",
      "Winner: Fast (reward difference: 0.2997)\n"
     ]
    }
   ],
   "source": [
    "# Calculate rewards\n",
    "slow_reward = energy_reward(r_slow)\n",
    "fast_reward = energy_reward(r_fast)\n",
    "\n",
    "slow_em = r_slow.get(\"energy_metrics\") or {}\n",
    "fast_em = r_fast.get(\"energy_metrics\") or {}\n",
    "\n",
    "\n",
    "def format_energy(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} J\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} mJ\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} uJ\"\n",
    "    return f\"{value * 1e9:.3f} nJ\"\n",
    "\n",
    "\n",
    "def format_time(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} s\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} ms\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} us\"\n",
    "    return f\"{value * 1e9:.3f} ns\"\n",
    "\n",
    "\n",
    "def format_power(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} W\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} mW\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} uW\"\n",
    "    return f\"{value * 1e9:.3f} nW\"\n",
    "\n",
    "\n",
    "def pad(text):\n",
    "    return f\"{text:<20}\"\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENERGY EFFICIENCY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"{'Metric':<30} {pad('Slow (Recursive)')} {pad('Fast (Iterative)')}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Status':<30} {pad(r_slow.get('status', 'n/a'))} {pad(r_fast.get('status', 'n/a'))}\")\n",
    "print(f\"{'Correctness':<30} {pad(str(r_slow.get('validation', {}).get('is_correct')))} {pad(str(r_fast.get('validation', {}).get('is_correct')))}\")\n",
    "print(f\"{'Energy':<30} {pad(format_energy(slow_em.get('median_total_energy_joules')))} {pad(format_energy(fast_em.get('median_total_energy_joules')))}\")\n",
    "print(f\"{'Time':<30} {pad(format_time(slow_em.get('median_execution_time_seconds')))} {pad(format_time(fast_em.get('median_execution_time_seconds')))}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'REWARD SCORE':<30} {slow_reward:<20.4f} {fast_reward:<20.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "winner = \"Fast\" if fast_reward > slow_reward else (\"Slow\" if slow_reward > fast_reward else \"Tie\")\n",
    "print(f\"Winner: {winner} (reward difference: {abs(fast_reward - slow_reward):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3e8eb",
   "metadata": {},
   "source": [
    "## Statistical Validation\n",
    "\n",
    "Run multiple trials to verify the reward function consistently identifies the more efficient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7086b473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3 comparison trials...\n",
      "\n",
      "Trial 1/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: completed\n",
      "  Slow: 0.4356, Fast: 0.7229\n",
      "\n",
      "Trial 2/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: completed\n",
      "  Slow: 0.3853, Fast: 0.6354\n",
      "\n",
      "Trial 3/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: completed\n",
      "  Slow: 0.4351, Fast: 0.7309\n",
      "\n",
      "==================================================\n",
      "Average rewards over 3 runs:\n",
      "  Slow (recursive): 0.4187\n",
      "  Fast (iterative): 0.6964\n",
      "  Difference: 0.2777\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def run_single_comparison():\n",
    "    \"\"\"Run one complete comparison of both candidates.\"\"\"\n",
    "    q1 = queue_job(candidate_slow, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "    q2 = queue_job(candidate_fast, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "    r1 = poll_from_poll_url(q1[\"poll_url\"])\n",
    "    r2 = poll_from_poll_url(q2[\"poll_url\"])\n",
    "    #return energy_reward(r1, t_budget_s=0.5), energy_reward(r2, t_budget_s=0.5)\n",
    "    return energy_reward(r1), energy_reward(r2)\n",
    "\n",
    "# Run multiple comparisons\n",
    "num_runs = 3\n",
    "slow_rewards, fast_rewards = [], []\n",
    "\n",
    "print(f\"Running {num_runs} comparison trials...\\n\")\n",
    "for i in range(num_runs):\n",
    "    print(f\"Trial {i+1}/{num_runs}:\")\n",
    "    sr, fr = run_single_comparison()\n",
    "    slow_rewards.append(sr)\n",
    "    fast_rewards.append(fr)\n",
    "    print(f\"  Slow: {sr:.4f}, Fast: {fr:.4f}\\n\")\n",
    "\n",
    "# Calculate averages\n",
    "avg_slow = sum(slow_rewards) / len(slow_rewards)\n",
    "avg_fast = sum(fast_rewards) / len(fast_rewards)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average rewards over {num_runs} runs:\")\n",
    "print(f\"  Slow (recursive): {avg_slow:.4f}\")\n",
    "print(f\"  Fast (iterative): {avg_fast:.4f}\")\n",
    "print(f\"  Difference: {avg_fast - avg_slow:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048345",
   "metadata": {},
   "source": [
    "#LCS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bab62de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_reward(result_json: dict,\n",
    "                  ref_energy_j: float = 1.0,\n",
    "                  ref_time_s: float = 0.01,\n",
    "                  beta_energy: float = 1.5,\n",
    "                  k_energy: float = 1.2,\n",
    "                  k_time: float = 1.0,\n",
    "                  hard_cap_multiple: float = 50.0) -> float:\n",
    "    \"\"\"\n",
    "    Reward in [0,1], higher is better.\n",
    "    - Monotonically decreases with energy and time.\n",
    "    - Diminishing returns when already below the reference.\n",
    "    - Harmonic blending emphasizes the worse dimension.\n",
    "\n",
    "    Transform:\n",
    "      s(r; k) = 1 / (1 + r**k), where r is ratio to reference (>=0).\n",
    "      r = value / reference. If r = 1 => s = 0.5. If r << 1 => s -> 1. If r >> 1 => s -> 0.\n",
    "    Blend:\n",
    "      F_beta-like harmonic mean: R = (1 + beta^2) * (Se * St) / (beta^2 * Se + St)\n",
    "    \"\"\"\n",
    "    if result_json.get(\"status\") != \"completed\":\n",
    "        return 0.0\n",
    "\n",
    "    validation = result_json.get(\"validation\") or {}\n",
    "    if not validation.get(\"is_correct\", False):\n",
    "        return 0.0\n",
    "\n",
    "    em = result_json.get(\"energy_metrics\") or {}\n",
    "    E = em.get(\"median_total_energy_joules\")\n",
    "    T = em.get(\"median_execution_time_seconds\")\n",
    "    if E is None or T is None or E < 0 or T < 0:\n",
    "        return 0.0\n",
    "\n",
    "    if E > hard_cap_multiple * ref_energy_j or T > hard_cap_multiple * ref_time_s:\n",
    "        return 0.0\n",
    "\n",
    "    safe_ref_energy = max(ref_energy_j, 1e-12)\n",
    "    safe_ref_time = max(ref_time_s, 1e-12)\n",
    "\n",
    "    rE = E / safe_ref_energy\n",
    "    rT = T / safe_ref_time\n",
    "\n",
    "    Se = 1.0 / (1.0 + (rE ** k_energy))\n",
    "    St = 1.0 / (1.0 + (rT ** k_time))\n",
    "\n",
    "    beta2 = beta_energy * beta_energy\n",
    "    denom = beta2 * Se + St\n",
    "    if denom <= 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    reward = (1.0 + beta2) * (Se * St) / denom\n",
    "    if not (reward == reward):\n",
    "        return 0.0\n",
    "\n",
    "    return float(max(0.0, min(1.0, reward)))\n",
    "\n",
    "\n",
    "def summarize_energy(result_json: dict) -> dict:\n",
    "    em = result_json.get(\"energy_metrics\") or {}\n",
    "    return {\n",
    "        \"package_J\": em.get(\"median_package_energy_joules\"),\n",
    "        \"ram_J\": em.get(\"median_ram_energy_joules\"),\n",
    "        \"total_J\": em.get(\"median_total_energy_joules\"),\n",
    "        \"time_s\": em.get(\"median_execution_time_seconds\"),\n",
    "        \"power_W\": em.get(\"power_consumption_watts\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_with_units(value, thresholds_units, scale):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    for threshold, unit in thresholds_units:\n",
    "        if abs_value >= threshold:\n",
    "            return f\"{value / scale[unit]:.3f} {unit}\"\n",
    "    unit = thresholds_units[-1][1]\n",
    "    return f\"{value / scale[unit]:.3f} {unit}\"\n",
    "\n",
    "\n",
    "def format_energy(value):\n",
    "    thresholds = ((1.0, \"J\"), (1e-3, \"mJ\"), (1e-6, \"uJ\"), (1e-9, \"nJ\"), (0.0, \"pJ\"))\n",
    "    scale = {\"J\": 1.0, \"mJ\": 1e-3, \"uJ\": 1e-6, \"nJ\": 1e-9, \"pJ\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def format_time(value):\n",
    "    thresholds = ((1.0, \"s\"), (1e-3, \"ms\"), (1e-6, \"us\"), (1e-9, \"ns\"), (0.0, \"ps\"))\n",
    "    scale = {\"s\": 1.0, \"ms\": 1e-3, \"us\": 1e-6, \"ns\": 1e-9, \"ps\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def format_power(value):\n",
    "    thresholds = ((1.0, \"W\"), (1e-3, \"mW\"), (1e-6, \"uW\"), (1e-9, \"nW\"), (0.0, \"pW\"))\n",
    "    scale = {\"W\": 1.0, \"mW\": 1e-3, \"uW\": 1e-6, \"nW\": 1e-9, \"pW\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def pad(text: str, width: int = 22) -> str:\n",
    "    return f\"{text:<{width}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0963d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('small_20x24', 20, 24), ('medium_60x65', 60, 65), ('large_120x130', 120, 130)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def lcs_reference(a: str, b: str) -> int:\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(m - 1, -1, -1):\n",
    "        ai = a[i]\n",
    "        row = dp[i]\n",
    "        row_next = dp[i + 1]\n",
    "        for j in range(n - 1, -1, -1):\n",
    "            if ai == b[j]:\n",
    "                row[j] = 1 + row_next[j + 1]\n",
    "            else:\n",
    "                row[j] = row[j + 1] if row[j + 1] >= row_next[j] else row_next[j]\n",
    "    return dp[0][0]\n",
    "\n",
    "\n",
    "rng = random.Random(1234)\n",
    "alphabet = \"abcd\"\n",
    "sizes = [\n",
    "    (20, 24, \"small\"),\n",
    "    (60, 65, \"medium\"),\n",
    "    (120, 130, \"large\"),\n",
    "]\n",
    "\n",
    "tests_lcs = []\n",
    "for m, n, label in sizes:\n",
    "    a = \"\".join(rng.choice(alphabet) for _ in range(m))\n",
    "    b = \"\".join(rng.choice(alphabet) for _ in range(n))\n",
    "    expected = lcs_reference(a, b)\n",
    "    tests_lcs.append({\n",
    "        \"test_id\": f\"{label}_{m}x{n}\",\n",
    "        \"inputs\": [a, b],\n",
    "        \"expected_output\": expected,\n",
    "    })\n",
    "\n",
    "pprint([(t[\"test_id\"], len(t[\"inputs\"][0]), len(t[\"inputs\"][1])) for t in tests_lcs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25acb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests prepared above; this cell intentionally left simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b6e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates: ['fast_dp', 'slow_dp', 'glacial_dp']\n"
     ]
    }
   ],
   "source": [
    "candidates_lcs = {\n",
    "    \"fast_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m-1, -1, -1):\n",
    "        ai = a[i]\n",
    "        row = dp[i]\n",
    "        row_next = dp[i+1]\n",
    "        for j in range(n-1, -1, -1):\n",
    "            if ai == b[j]:\n",
    "                row[j] = 1 + row_next[j+1]\n",
    "            else:\n",
    "                row[j] = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "    return dp[0][0]\n",
    "\"\"\",\n",
    "    \"slow_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    res = 0\n",
    "    for _ in range(12):   # recompute DP 12 times\n",
    "        dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "        for i in range(m-1, -1, -1):\n",
    "            ai = a[i]\n",
    "            row = dp[i]\n",
    "            row_next = dp[i+1]\n",
    "            for j in range(n-1, -1, -1):\n",
    "                if ai == b[j]:\n",
    "                    row[j] = 1 + row_next[j+1]\n",
    "                else:\n",
    "                    row[j] = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "        res = dp[0][0]\n",
    "    return res\n",
    "\"\"\",\n",
    "    \"glacial_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    res = 0\n",
    "    for repeat in range(45):   # heavy recomputation with extra work\n",
    "        dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "        for i in range(m-1, -1, -1):\n",
    "            ai = a[i]\n",
    "            row = dp[i]\n",
    "            row_next = dp[i+1]\n",
    "            for j in range(n-1, -1, -1):\n",
    "                if ai == b[j]:\n",
    "                    val = 1 + row_next[j+1]\n",
    "                else:\n",
    "                    val = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "                tmp = val\n",
    "                for _ in range(12):\n",
    "                    tmp = tmp if tmp >= val else val\n",
    "                row[j] = tmp\n",
    "        res = dp[0][0]\n",
    "    return res\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Candidates:\", list(candidates_lcs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5678a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting fast_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "fast_dp: status=completed reward=0.6575\n",
      "Submitting slow_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "slow_dp: status=completed reward=0.2912\n",
      "Submitting glacial_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "glacial_dp: status=completed reward=0.0250\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def measure_candidate(code: str,\n",
    "                      function_name: str,\n",
    "                      tests: list,\n",
    "                      timeout_seconds: int = 40,\n",
    "                      trials: int = 3,\n",
    "                      warmup: int = 1) -> dict:\n",
    "    queued = queue_job(code, function_name, tests,\n",
    "                       timeout_seconds=timeout_seconds,\n",
    "                       memory_limit_mb=2048,\n",
    "                       trials=trials,\n",
    "                       warmup=warmup)\n",
    "    if isinstance(queued, dict) and \"poll_url\" in queued:\n",
    "        return poll_from_poll_url(queued[\"poll_url\"])\n",
    "    return queued\n",
    "\n",
    "\n",
    "results_lcs = {}\n",
    "for name, code in candidates_lcs.items():\n",
    "    print(f\"Submitting {name}...\")\n",
    "    result = measure_candidate(code, \"solve\", tests_lcs)\n",
    "    reward = energy_reward(result)\n",
    "    energy_summary = summarize_energy(result)\n",
    "    results_lcs[name] = {\n",
    "        \"status\": result.get(\"status\"),\n",
    "        \"validation\": result.get(\"validation\"),\n",
    "        \"reward\": reward,\n",
    "        \"energy\": energy_summary,\n",
    "        \"raw_result\": result,\n",
    "    }\n",
    "    print(f\"{name}: status={results_lcs[name]['status']} reward={reward:.4f}\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75bea393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy measurement cell replaced by the helper above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a6a3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         LCS CANDIDATE EFFICIENCY                         \n",
      "================================================================================\n",
      "Candidate     Reward    Energy            Time            Power\n",
      "--------------------------------------------------------------------------------\n",
      "fast_dp       0.6575    1.240 J               1.770 ms              700.537 W\n",
      "slow_dp       0.2912    2.750 J               20.197 ms             136.161 W\n",
      "glacial_dp    0.0250    20.770 J              393.558 ms            52.775 W\n",
      "--------------------------------------------------------------------------------\n",
      "Best reward: fast_dp (0.6575)\n",
      "Energy details:\n",
      "     fast_dp | package=1.150 J, ram=90.000 mJ, total=1.240 J, time=1.770 ms, power=700.537 W\n",
      "     slow_dp | package=2.450 J, ram=310.000 mJ, total=2.750 J, time=20.197 ms, power=136.161 W\n",
      "  glacial_dp | package=19.290 J, ram=1.480 J, total=20.770 J, time=393.558 ms, power=52.775 W\n"
     ]
    }
   ],
   "source": [
    "if not results_lcs:\n",
    "    print(\"No LCS results available.\")\n",
    "else:\n",
    "    rows = sorted(\n",
    "        results_lcs.items(),\n",
    "        key=lambda item: item[1].get(\"reward\", 0.0),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"LCS CANDIDATE EFFICIENCY\".center(74))\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Candidate':<14}{'Reward':<10}{'Energy':<18}{'Time':<16}{'Power'}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for name, info in rows:\n",
    "        energy = info.get(\"energy\") or {}\n",
    "        print(f\"{name:<14}\"\n",
    "              f\"{info.get('reward', 0.0):<10.4f}\"\n",
    "              f\"{pad(format_energy(energy.get('total_J')))}\"\n",
    "              f\"{pad(format_time(energy.get('time_s')))}\"\n",
    "              f\"{format_power(energy.get('power_W'))}\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    best_name, best_info = rows[0]\n",
    "    print(f\"Best reward: {best_name} ({best_info.get('reward', 0.0):.4f})\")\n",
    "\n",
    "    print(\"Energy details:\")\n",
    "    for name, info in results_lcs.items():\n",
    "        energy = info.get(\"energy\") or {}\n",
    "        print(f\"{name:>12} | \"\n",
    "              f\"package={format_energy(energy.get('package_J'))}, \"\n",
    "              f\"ram={format_energy(energy.get('ram_J'))}, \"\n",
    "              f\"total={format_energy(energy.get('total_J'))}, \"\n",
    "              f\"time={format_time(energy.get('time_s'))}, \"\n",
    "              f\"power={format_power(energy.get('power_W'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd866e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
