{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9ad651",
   "metadata": {},
   "source": [
    "## Energy-Based Reward Function Demo\n",
    "\n",
    "This demo shows how we can use JouleTrace to compare two algorithms solving the same problem, and assign rewards based on their energy efficiency and execution time.\n",
    "\n",
    "**Scenario**: Computing Fibonacci numbers\n",
    "- **Fast candidate**: Iterative O(n) algorithm\n",
    "- **Slow candidate**: Naive recursive algorithm (exponential complexity)\n",
    "\n",
    "Both produce correct results, but we'll see how the reward function prefers the more efficient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf2865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# JouleTrace API configuration\n",
    "JOULETRACE_BASE_URL = os.getenv(\"JOULETRACE_BASE_URL\", \"http://127.0.0.1:8000\")\n",
    "MEASURE_URL = f\"{JOULETRACE_BASE_URL}/api/v1/measure\"\n",
    "\n",
    "def poll_from_poll_url(poll_url: str, timeout_s: int = 600, interval_s: float = 0.5):\n",
    "    \"\"\"Poll a JouleTrace task until completion.\"\"\"\n",
    "    url = poll_url if poll_url.startswith(\"http\") else f\"{JOULETRACE_BASE_URL}{poll_url}\"\n",
    "    start = time.time()\n",
    "    last_status = None\n",
    "    \n",
    "    while True:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        status = data.get(\"status\")\n",
    "        \n",
    "        if status != last_status:\n",
    "            print(f\"Status: {status}\")\n",
    "            last_status = status\n",
    "            \n",
    "        if status in {\"completed\", \"failed\"}:\n",
    "            return data\n",
    "            \n",
    "        if time.time() - start > timeout_s:\n",
    "            raise TimeoutError(f\"Polling timed out after {timeout_s}s\")\n",
    "            \n",
    "        time.sleep(interval_s)\n",
    "\n",
    "def queue_job(candidate_code, function_name, tests, timeout_seconds=15,\n",
    "              memory_limit_mb=2048, trials=3, warmup=1):\n",
    "    payload = {\n",
    "        \"candidate_code\": candidate_code,\n",
    "        \"function_name\": function_name,\n",
    "        \"test_cases\": tests,\n",
    "        \"timeout_seconds\": timeout_seconds,\n",
    "        \"memory_limit_mb\": memory_limit_mb,\n",
    "        \"energy_measurement_trials\": trials,\n",
    "        \"warmup_trials\": warmup,\n",
    "    }\n",
    "    return requests.post(MEASURE_URL, json=payload, timeout=60).json()\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032bf7a8",
   "metadata": {},
   "source": [
    "## Define Candidate Algorithms\n",
    "\n",
    "We'll compare two implementations:\n",
    "1. **Fast (Iterative)**: O(n) time complexity, minimal memory usage\n",
    "2. **Slow (Naive Recursive)**: O(2^n) time complexity, significant call stack overhead\n",
    "\n",
    "Both are functionally correct, but dramatically different in efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe32713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast candidate (iterative):\n",
      "def solve(n):\n",
      "    a, b = 0, 1\n",
      "    for _ in range(n):\n",
      "        a, b = b, a + b\n",
      "    return a\n",
      "\n",
      "\n",
      "Slow candidate (recursive):\n",
      "def solve(n):\n",
      "    if n < 2:\n",
      "        return n\n",
      "    return solve(n-1) + solve(n-2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fast candidate: Iterative approach (O(n))\n",
    "candidate_fast = \"\"\"\\\n",
    "def solve(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\"\"\"\n",
    "\n",
    "# Slow candidate: Naive recursion (O(2^n))\n",
    "candidate_slow = \"\"\"\\\n",
    "def solve(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return solve(n-1) + solve(n-2)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Fast candidate (iterative):\")\n",
    "print(candidate_fast)\n",
    "print(\"\\nSlow candidate (recursive):\")\n",
    "print(candidate_slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee2b4a",
   "metadata": {},
   "source": [
    "## Generate Test Cases\n",
    "\n",
    "We'll use modest Fibonacci indices (22, 24) so that even the slow recursive version completes within a reasonable timeout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac72d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cases:\n",
      "[{'expected_output': 17711, 'inputs': [22], 'test_id': 'fib-22'},\n",
      " {'expected_output': 46368, 'inputs': [24], 'test_id': 'fib-24'}]\n"
     ]
    }
   ],
   "source": [
    "# Local reference implementation to generate expected outputs\n",
    "def fib_ref(n: int) -> int:\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\n",
    "# Generate test cases\n",
    "test_inputs = [22, 24]\n",
    "tests = [\n",
    "    {\n",
    "        \"test_id\": f\"fib-{n}\",\n",
    "        \"inputs\": [n],\n",
    "        \"expected_output\": fib_ref(n)\n",
    "    }\n",
    "    for n in test_inputs\n",
    "]\n",
    "\n",
    "print(\"Test cases:\")\n",
    "pprint(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808958e7",
   "metadata": {},
   "source": [
    "# Energy Reward Function\n",
    "\n",
    "This reward function produces a score in **[0,1]**, where higher is better. It integrates **correctness**, **energy efficiency**, and **execution speed** in a balanced way.\n",
    "\n",
    "## Key Principles\n",
    "\n",
    "1. **Correctness Gate**  \n",
    "   - If the result is not completed or fails validation, reward = **0.0**.  \n",
    "   - Only correct results are eligible for scoring.\n",
    "\n",
    "2. **Energy and Time Scaling**  \n",
    "   - Define ratios relative to reference baselines:\n",
    "     - $r_E = \\frac{E}{E_{\\text{ref}}}$  \n",
    "     - $r_T = \\frac{T}{T_{\\text{ref}}}$\n",
    "   - Transform with a bounded monotone function:\n",
    "   \n",
    "   $$s(r; k) = \\frac{1}{1 + r^k}$$\n",
    "   \n",
    "   where $k$ controls steepness.\n",
    "     - $r = 1 \\Rightarrow s = 0.5$  \n",
    "     - $r \\ll 1 \\Rightarrow s \\to 1$ (very efficient)  \n",
    "     - $r \\gg 1 \\Rightarrow s \\to 0$ (very inefficient)  \n",
    "\n",
    "3. **Blending ($F_\\beta$-style harmonic mean)**  \n",
    "   - Combine energy score $S_E$ and time score $S_T$ as:\n",
    "   \n",
    "   $$R = \\frac{(1+\\beta^2) \\cdot (S_E \\cdot S_T)}{\\beta^2 \\cdot S_E + S_T}$$\n",
    "   \n",
    "   - $\\beta > 1$: emphasizes **energy** efficiency.  \n",
    "   - $\\beta < 1$: emphasizes **time** efficiency.  \n",
    "   - Ensures the weaker dimension dominates the overall score.\n",
    "\n",
    "4. **Hard Cap Safeguard**  \n",
    "   - If energy or time exceeds a multiple of the reference (e.g., 50×), reward collapses to **0.0**.  \n",
    "   - Prevents absurdly bad results from skewing comparisons.\n",
    "\n",
    "## Properties\n",
    "\n",
    "- **Range:** Strictly bounded to [0,1].  \n",
    "- **Smoothness:** Diminishing returns when already efficient.  \n",
    "- **Fairness:** Penalizes whichever metric (energy or time) is worse.  \n",
    "- **Robustness:** NaN- and outlier-safe.\n",
    "\n",
    "---\n",
    "\n",
    "**Key fixes:**\n",
    "- Added blank lines before and after `$$...$$` display math blocks\n",
    "- Changed `E_{ref}` and `T_{ref}` to `E_{\\text{ref}}` and `T_{\\text{ref}}` for proper subscript formatting\n",
    "- Ensured no text immediately follows the closing `$$`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd58fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_reward(result_json: dict,\n",
    "                     ref_energy_j: float = 1.0,\n",
    "                     ref_time_s: float = 0.01,\n",
    "                     beta_energy: float = 1.5,   # >1 emphasizes energy over time; <1 does the opposite\n",
    "                     k_energy: float = 1.2,      # steepness for energy penalty\n",
    "                     k_time: float = 1.0,        # steepness for time penalty\n",
    "                     hard_cap_multiple: float = 50.0):\n",
    "    \"\"\"\n",
    "    Reward in [0,1], higher is better.\n",
    "    - Monotonically decreases with energy and time.\n",
    "    - Diminishing returns when already below the reference.\n",
    "    - Harmonic blending emphasizes the worse dimension.\n",
    "\n",
    "    Transform:\n",
    "      s(r; k) = 1 / (1 + r^k), where r is ratio to reference (>=0).\n",
    "      r = value / reference. If r=1 => s=0.5. If r<<1 => s→1. If r>>1 => s→0.\n",
    "    Blend:\n",
    "      F_beta-like harmonic mean: R = (1+β^2) * (Se * St) / (β^2 * Se + St)\n",
    "    \"\"\"\n",
    "\n",
    "    # Basic validity checks\n",
    "    if result_json.get(\"status\") != \"completed\":\n",
    "        return 0.0\n",
    "    validation = result_json.get(\"validation\") or {}\n",
    "    if not validation.get(\"is_correct\", False):\n",
    "        return 0.0\n",
    "\n",
    "    em = result_json.get(\"energy_metrics\") or {}\n",
    "    E = em.get(\"median_total_energy_joules\")\n",
    "    T = em.get(\"median_execution_time_seconds\")\n",
    "    if E is None or T is None or E < 0 or T < 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Optional hard cap: if absurdly worse than reference, collapse reward\n",
    "    if E > hard_cap_multiple * ref_energy_j or T > hard_cap_multiple * ref_time_s:\n",
    "        return 0.0\n",
    "\n",
    "    # Dimensionless ratios\n",
    "    rE = E / max(ref_energy_j, 1e-12)\n",
    "    rT = T / max(ref_time_s, 1e-12)\n",
    "\n",
    "    # Smooth, bounded, monotone scores (1 is best, 0 is worst)\n",
    "    Se = 1.0 / (1.0 + (rE ** k_energy))\n",
    "    St = 1.0 / (1.0 + (rT ** k_time))\n",
    "\n",
    "    # F_beta-style harmonic mean emphasizing the weaker side\n",
    "    beta2 = beta_energy * beta_energy\n",
    "    denom = (beta2 * Se + St)\n",
    "    if denom <= 0:\n",
    "        return 0.0\n",
    "    reward = (1.0 + beta2) * (Se * St) / denom\n",
    "\n",
    "    # Numerical safety & clamp\n",
    "    if not (reward == reward):  # NaN check\n",
    "        return 0.0\n",
    "    return float(max(0.0, min(1.0, reward)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bc6fe",
   "metadata": {},
   "source": [
    "## Run Energy Measurements\n",
    "\n",
    "Now we'll measure both candidates with JouleTrace and calculate their rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a8f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queueing slow candidate...\n",
      "Queueing fast candidate...\n",
      "\n",
      "Polling slow candidate...\n",
      "Status: running\n",
      "Status: completed\n",
      "\n",
      "Polling fast candidate...\n",
      "Status: completed\n",
      "\n",
      "Both measurements complete\n"
     ]
    }
   ],
   "source": [
    "print(\"Queueing slow candidate...\")\n",
    "q_slow = queue_job(candidate_slow, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "\n",
    "print(\"Queueing fast candidate...\")\n",
    "q_fast = queue_job(candidate_fast, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "\n",
    "print(\"\\nPolling slow candidate...\")\n",
    "r_slow = poll_from_poll_url(q_slow[\"poll_url\"])\n",
    "\n",
    "print(\"\\nPolling fast candidate...\")\n",
    "r_fast = poll_from_poll_url(q_fast[\"poll_url\"])\n",
    "\n",
    "print(\"\\nBoth measurements complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78875e5",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "\n",
    "Let's calculate rewards and compare the two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8801bf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ENERGY EFFICIENCY COMPARISON\n",
      "======================================================================\n",
      "Metric                         Slow (Recursive)     Fast (Iterative)    \n",
      "----------------------------------------------------------------------\n",
      "Status                         completed            completed           \n",
      "Correctness                    True                 True                \n",
      "Energy                         2.460 J              1.730 J             \n",
      "Time                           9.988 ms             6.283 us            \n",
      "----------------------------------------------------------------------\n",
      "REWARD SCORE                   0.3850               0.6272              \n",
      "======================================================================\n",
      "Winner: Fast (reward difference: 0.2422)\n"
     ]
    }
   ],
   "source": [
    "# Calculate rewards\n",
    "slow_reward = energy_reward(r_slow)\n",
    "fast_reward = energy_reward(r_fast)\n",
    "\n",
    "slow_em = r_slow.get(\"energy_metrics\") or {}\n",
    "fast_em = r_fast.get(\"energy_metrics\") or {}\n",
    "\n",
    "\n",
    "def format_energy(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} J\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} mJ\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} uJ\"\n",
    "    return f\"{value * 1e9:.3f} nJ\"\n",
    "\n",
    "\n",
    "def format_time(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} s\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} ms\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} us\"\n",
    "    return f\"{value * 1e9:.3f} ns\"\n",
    "\n",
    "\n",
    "def format_power(value):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    if abs_value >= 1:\n",
    "        return f\"{value:.3f} W\"\n",
    "    if abs_value >= 1e-3:\n",
    "        return f\"{value * 1e3:.3f} mW\"\n",
    "    if abs_value >= 1e-6:\n",
    "        return f\"{value * 1e6:.3f} uW\"\n",
    "    return f\"{value * 1e9:.3f} nW\"\n",
    "\n",
    "\n",
    "def pad(text):\n",
    "    return f\"{text:<20}\"\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ENERGY EFFICIENCY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"{'Metric':<30} {pad('Slow (Recursive)')} {pad('Fast (Iterative)')}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Status':<30} {pad(r_slow.get('status', 'n/a'))} {pad(r_fast.get('status', 'n/a'))}\")\n",
    "print(f\"{'Correctness':<30} {pad(str(r_slow.get('validation', {}).get('is_correct')))} {pad(str(r_fast.get('validation', {}).get('is_correct')))}\")\n",
    "print(f\"{'Energy':<30} {pad(format_energy(slow_em.get('median_total_energy_joules')))} {pad(format_energy(fast_em.get('median_total_energy_joules')))}\")\n",
    "print(f\"{'Time':<30} {pad(format_time(slow_em.get('median_execution_time_seconds')))} {pad(format_time(fast_em.get('median_execution_time_seconds')))}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'REWARD SCORE':<30} {slow_reward:<20.4f} {fast_reward:<20.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "winner = \"Fast\" if fast_reward > slow_reward else (\"Slow\" if slow_reward > fast_reward else \"Tie\")\n",
    "print(f\"Winner: {winner} (reward difference: {abs(fast_reward - slow_reward):.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3e8eb",
   "metadata": {},
   "source": [
    "## Statistical Validation\n",
    "\n",
    "Run multiple trials to verify the reward function consistently identifies the more efficient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7086b473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 3 comparison trials...\n",
      "\n",
      "Trial 1/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: completed\n",
      "  Slow: 0.4461, Fast: 0.6734\n",
      "\n",
      "Trial 2/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: completed\n",
      "  Slow: 0.3862, Fast: 0.6321\n",
      "\n",
      "Trial 3/3:\n",
      "Status: running\n",
      "Status: completed\n",
      "Status: running\n",
      "Status: completed\n",
      "  Slow: 0.4464, Fast: 0.7350\n",
      "\n",
      "==================================================\n",
      "Average rewards over 3 runs:\n",
      "  Slow (recursive): 0.4262\n",
      "  Fast (iterative): 0.6802\n",
      "  Difference: 0.2540\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def run_single_comparison():\n",
    "    \"\"\"Run one complete comparison of both candidates.\"\"\"\n",
    "    q1 = queue_job(candidate_slow, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "    q2 = queue_job(candidate_fast, \"solve\", tests, timeout_seconds=15, trials=3, warmup=1)\n",
    "    r1 = poll_from_poll_url(q1[\"poll_url\"])\n",
    "    r2 = poll_from_poll_url(q2[\"poll_url\"])\n",
    "    #return energy_reward(r1, t_budget_s=0.5), energy_reward(r2, t_budget_s=0.5)\n",
    "    return energy_reward(r1), energy_reward(r2)\n",
    "\n",
    "# Run multiple comparisons\n",
    "num_runs = 3\n",
    "slow_rewards, fast_rewards = [], []\n",
    "\n",
    "print(f\"Running {num_runs} comparison trials...\\n\")\n",
    "for i in range(num_runs):\n",
    "    print(f\"Trial {i+1}/{num_runs}:\")\n",
    "    sr, fr = run_single_comparison()\n",
    "    slow_rewards.append(sr)\n",
    "    fast_rewards.append(fr)\n",
    "    print(f\"  Slow: {sr:.4f}, Fast: {fr:.4f}\\n\")\n",
    "\n",
    "# Calculate averages\n",
    "avg_slow = sum(slow_rewards) / len(slow_rewards)\n",
    "avg_fast = sum(fast_rewards) / len(fast_rewards)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Average rewards over {num_runs} runs:\")\n",
    "print(f\"  Slow (recursive): {avg_slow:.4f}\")\n",
    "print(f\"  Fast (iterative): {avg_fast:.4f}\")\n",
    "print(f\"  Difference: {avg_fast - avg_slow:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048345",
   "metadata": {},
   "source": [
    "# LCS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab62de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_energy(result_json: dict) -> dict:\n",
    "    em = result_json.get(\"energy_metrics\") or {}\n",
    "    return {\n",
    "        \"package_J\": em.get(\"median_package_energy_joules\"),\n",
    "        \"ram_J\": em.get(\"median_ram_energy_joules\"),\n",
    "        \"total_J\": em.get(\"median_total_energy_joules\"),\n",
    "        \"time_s\": em.get(\"median_execution_time_seconds\"),\n",
    "        \"power_W\": em.get(\"power_consumption_watts\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def _format_with_units(value, thresholds_units, scale):\n",
    "    if value is None:\n",
    "        return \"n/a\"\n",
    "    abs_value = abs(value)\n",
    "    for threshold, unit in thresholds_units:\n",
    "        if abs_value >= threshold:\n",
    "            return f\"{value / scale[unit]:.3f} {unit}\"\n",
    "    unit = thresholds_units[-1][1]\n",
    "    return f\"{value / scale[unit]:.3f} {unit}\"\n",
    "\n",
    "\n",
    "def format_energy(value):\n",
    "    thresholds = ((1.0, \"J\"), (1e-3, \"mJ\"), (1e-6, \"uJ\"), (1e-9, \"nJ\"), (0.0, \"pJ\"))\n",
    "    scale = {\"J\": 1.0, \"mJ\": 1e-3, \"uJ\": 1e-6, \"nJ\": 1e-9, \"pJ\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def format_time(value):\n",
    "    thresholds = ((1.0, \"s\"), (1e-3, \"ms\"), (1e-6, \"us\"), (1e-9, \"ns\"), (0.0, \"ps\"))\n",
    "    scale = {\"s\": 1.0, \"ms\": 1e-3, \"us\": 1e-6, \"ns\": 1e-9, \"ps\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def format_power(value):\n",
    "    thresholds = ((1.0, \"W\"), (1e-3, \"mW\"), (1e-6, \"uW\"), (1e-9, \"nW\"), (0.0, \"pW\"))\n",
    "    scale = {\"W\": 1.0, \"mW\": 1e-3, \"uW\": 1e-6, \"nW\": 1e-9, \"pW\": 1e-12}\n",
    "    return _format_with_units(value, thresholds, scale)\n",
    "\n",
    "\n",
    "def pad(text: str, width: int = 22) -> str:\n",
    "    return f\"{text:<{width}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0963d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('small_20x24', 20, 24), ('medium_60x65', 60, 65), ('large_120x130', 120, 130)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def lcs_reference(a: str, b: str) -> int:\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "    for i in range(m - 1, -1, -1):\n",
    "        ai = a[i]\n",
    "        row = dp[i]\n",
    "        row_next = dp[i + 1]\n",
    "        for j in range(n - 1, -1, -1):\n",
    "            if ai == b[j]:\n",
    "                row[j] = 1 + row_next[j + 1]\n",
    "            else:\n",
    "                row[j] = row[j + 1] if row[j + 1] >= row_next[j] else row_next[j]\n",
    "    return dp[0][0]\n",
    "\n",
    "\n",
    "rng = random.Random(1234)\n",
    "alphabet = \"abcd\"\n",
    "sizes = [\n",
    "    (20, 24, \"small\"),\n",
    "    (60, 65, \"medium\"),\n",
    "    (120, 130, \"large\"),\n",
    "]\n",
    "\n",
    "tests_lcs = []\n",
    "for m, n, label in sizes:\n",
    "    a = \"\".join(rng.choice(alphabet) for _ in range(m))\n",
    "    b = \"\".join(rng.choice(alphabet) for _ in range(n))\n",
    "    expected = lcs_reference(a, b)\n",
    "    tests_lcs.append({\n",
    "        \"test_id\": f\"{label}_{m}x{n}\",\n",
    "        \"inputs\": [a, b],\n",
    "        \"expected_output\": expected,\n",
    "    })\n",
    "\n",
    "pprint([(t[\"test_id\"], len(t[\"inputs\"][0]), len(t[\"inputs\"][1])) for t in tests_lcs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25acb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests prepared above; this cell intentionally left simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b6e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates: ['fast_dp', 'slow_dp', 'glacial_dp']\n"
     ]
    }
   ],
   "source": [
    "candidates_lcs = {\n",
    "    \"fast_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m-1, -1, -1):\n",
    "        ai = a[i]\n",
    "        row = dp[i]\n",
    "        row_next = dp[i+1]\n",
    "        for j in range(n-1, -1, -1):\n",
    "            if ai == b[j]:\n",
    "                row[j] = 1 + row_next[j+1]\n",
    "            else:\n",
    "                row[j] = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "    return dp[0][0]\n",
    "\"\"\",\n",
    "    \"slow_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    res = 0\n",
    "    for _ in range(12):   # recompute DP 12 times\n",
    "        dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "        for i in range(m-1, -1, -1):\n",
    "            ai = a[i]\n",
    "            row = dp[i]\n",
    "            row_next = dp[i+1]\n",
    "            for j in range(n-1, -1, -1):\n",
    "                if ai == b[j]:\n",
    "                    row[j] = 1 + row_next[j+1]\n",
    "                else:\n",
    "                    row[j] = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "        res = dp[0][0]\n",
    "    return res\n",
    "\"\"\",\n",
    "    \"glacial_dp\": \"\"\"\\\n",
    "def solve(a, b):\n",
    "    m, n = len(a), len(b)\n",
    "    res = 0\n",
    "    for repeat in range(45):   # heavy recomputation with extra work\n",
    "        dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "        for i in range(m-1, -1, -1):\n",
    "            ai = a[i]\n",
    "            row = dp[i]\n",
    "            row_next = dp[i+1]\n",
    "            for j in range(n-1, -1, -1):\n",
    "                if ai == b[j]:\n",
    "                    val = 1 + row_next[j+1]\n",
    "                else:\n",
    "                    val = row[j+1] if row[j+1] >= row_next[j] else row_next[j]\n",
    "                tmp = val\n",
    "                for _ in range(12):\n",
    "                    tmp = tmp if tmp >= val else val\n",
    "                row[j] = tmp\n",
    "        res = dp[0][0]\n",
    "    return res\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Candidates:\", list(candidates_lcs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5678a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting fast_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "fast_dp: status=completed reward=0.6138\n",
      "Submitting slow_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "slow_dp: status=completed reward=0.3137\n",
      "Submitting glacial_dp...\n",
      "Status: running\n",
      "Status: completed\n",
      "glacial_dp: status=completed reward=0.0226\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def measure_candidate(code: str,\n",
    "                      function_name: str,\n",
    "                      tests: list,\n",
    "                      timeout_seconds: int = 40,\n",
    "                      trials: int = 3,\n",
    "                      warmup: int = 1) -> dict:\n",
    "    queued = queue_job(code, function_name, tests,\n",
    "                       timeout_seconds=timeout_seconds,\n",
    "                       memory_limit_mb=2048,\n",
    "                       trials=trials,\n",
    "                       warmup=warmup)\n",
    "    if isinstance(queued, dict) and \"poll_url\" in queued:\n",
    "        return poll_from_poll_url(queued[\"poll_url\"])\n",
    "    return queued\n",
    "\n",
    "\n",
    "results_lcs = {}\n",
    "for name, code in candidates_lcs.items():\n",
    "    print(f\"Submitting {name}...\")\n",
    "    result = measure_candidate(code, \"solve\", tests_lcs)\n",
    "    reward = energy_reward(result)\n",
    "    energy_summary = summarize_energy(result)\n",
    "    results_lcs[name] = {\n",
    "        \"status\": result.get(\"status\"),\n",
    "        \"validation\": result.get(\"validation\"),\n",
    "        \"reward\": reward,\n",
    "        \"energy\": energy_summary,\n",
    "        \"raw_result\": result,\n",
    "    }\n",
    "    print(f\"{name}: status={results_lcs[name]['status']} reward={reward:.4f}\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75bea393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy measurement cell replaced by the helper above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a6a3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         LCS CANDIDATE EFFICIENCY                         \n",
      "================================================================================\n",
      "Candidate     Reward    Energy            Time            Power\n",
      "--------------------------------------------------------------------------------\n",
      "fast_dp       0.6138    1.520 J               1.743 ms              871.891 W\n",
      "slow_dp       0.3137    2.130 J               20.595 ms             103.423 W\n",
      "glacial_dp    0.0226    26.950 J              394.148 ms            68.375 W\n",
      "--------------------------------------------------------------------------------\n",
      "Best reward: fast_dp (0.6138)\n",
      "Energy details:\n",
      "     fast_dp | package=1.350 J, ram=180.000 mJ, total=1.520 J, time=1.743 ms, power=871.891 W\n",
      "     slow_dp | package=1.980 J, ram=150.000 mJ, total=2.130 J, time=20.595 ms, power=103.423 W\n",
      "  glacial_dp | package=23.950 J, ram=3.000 J, total=26.950 J, time=394.148 ms, power=68.375 W\n"
     ]
    }
   ],
   "source": [
    "if not results_lcs:\n",
    "    print(\"No LCS results available.\")\n",
    "else:\n",
    "    rows = sorted(\n",
    "        results_lcs.items(),\n",
    "        key=lambda item: item[1].get(\"reward\", 0.0),\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"LCS CANDIDATE EFFICIENCY\".center(74))\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Candidate':<14}{'Reward':<10}{'Energy':<18}{'Time':<16}{'Power'}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for name, info in rows:\n",
    "        energy = info.get(\"energy\") or {}\n",
    "        print(f\"{name:<14}\"\n",
    "              f\"{info.get('reward', 0.0):<10.4f}\"\n",
    "              f\"{pad(format_energy(energy.get('total_J')))}\"\n",
    "              f\"{pad(format_time(energy.get('time_s')))}\"\n",
    "              f\"{format_power(energy.get('power_W'))}\")\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    best_name, best_info = rows[0]\n",
    "    print(f\"Best reward: {best_name} ({best_info.get('reward', 0.0):.4f})\")\n",
    "\n",
    "    print(\"Energy details:\")\n",
    "    for name, info in results_lcs.items():\n",
    "        energy = info.get(\"energy\") or {}\n",
    "        print(f\"{name:>12} | \"\n",
    "              f\"package={format_energy(energy.get('package_J'))}, \"\n",
    "              f\"ram={format_energy(energy.get('ram_J'))}, \"\n",
    "              f\"total={format_energy(energy.get('total_J'))}, \"\n",
    "              f\"time={format_time(energy.get('time_s'))}, \"\n",
    "              f\"power={format_power(energy.get('power_W'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd866e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
